---
output: github_document
---

# Adjusting for common biases in infectious disease data when estimating distributions.


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "figures/README-",
  out.width = "100%",
  dpi = 330,
  message = FALSE, warning = FALSE
)
```

## A simple example

First load required packages and functions.

```{r load-requirements}
library(data.table)
library(purrr, quietly = TRUE)
library(ggplot2)
library(patchwork)
library(here)
library(brms)
functions <- list.files(here("R"), full.names = TRUE)
walk(functions, source)
```

### Simulate the data

Simulate data from an outbreak.

```{r simulate-outbreak}
outbreak <- simulate_gillespie(seed = 101)
```

Define the secondary distribution to use in the simulation

```{r secondary-dist}
secondary_dist <- data.table(
  meanlog = 1.8, sdlog = 0.5
) |>
  add_natural_scale_mean_sd()
```

Simulate an observation process during the growth phase for a secondary event using a lognormal distribution, and finally simulate observing this event.

```{r simulate-data}
obs <- outbreak |>
  simulate_secondary(
    meanlog = secondary_dist$meanlog[[1]],
    sdlog = secondary_dist$sdlog[[1]]
  ) |>
  observe_process()
```

Observe the outbreak after 25 days and take 100 samples.

```{r observe-data}
truncated_obs <- obs |>
  filter_obs_by_obs_time(obs_time = 25) |>
  DT(sample(1:.N, 200, replace = FALSE))
```

Plot primary cases (dots), and secondary cases (columns) by observation window.

```{r observed-cases}
truncated_cases <- construct_cases_by_obs_window(
  obs, windows = c(25)
)

plot_cases_by_obs_window(truncated_cases)
```

Plot the true continuous delay distribution and the empirical observed distribution for each observation window.

```{r empirical-dist}
combined_obs <- combine_obs(truncated_obs, obs)

plot_empirical_delay(
  combined_obs, meanlog = secondary_dist$meanlog[[1]],
  sdlog = secondary_dist$sdlog[[1]]
)
```
### Models

First fit a naive lognormal model with no adjustment.

```{r}
naive_fit <- naive_delay(data = truncated_obs, cores = 4, refresh = 0)
```

Estimate the delay after filtering out the most recent data as crude adjustement for right truncation.

```{r}
filtered_fit <- filtered_naive_delay(
  data = truncated_obs, cores = 4, refresh = 0
)
```

Adjust for date censoring.

```{r}
censored_fit <- censoring_adjusted_delay(
  data = truncated_obs, cores = 4, refresh = 0
)
```

Adjust for censoring and filter to crudely adjust for right truncation.

```{r}
filtered_censored_fit <- filtered_censoring_adjusted_delay(
  data = truncated_obs, cores = 4, refresh = 0
)
```

Adjust for right truncation.

```{r}
truncation_fit <- truncation_adjusted_delay(
  data = truncated_obs, cores = 4, refresh = 0
)
```


Adjust for right truncation and date censoring.

```{r}
truncation_censoring_fit <- truncation_censoring_adjusted_delay(
  data = truncated_obs, cores = 4, refresh = 0
)
```

Adjust for right truncation and date censoring using a latent variable approach.

```{r}
latent_truncation_censoring_fit <- latent_truncation_censoring_adjusted_delay(
  data = truncated_obs, cores = 4, refresh = 0
)
```

### Summarise model posteriors and compare to known truth

Combine models into a named list.

```{r}
models <- list(
  "Naive" = naive_fit,
  "Filtered" = filtered_fit,
  "Censoring adjusted" = censored_fit,
  "Filtered and censoring adjusted" = filtered_censored_fit,
  "Truncation adjusted" = truncation_fit,
  "Truncation and censoring adjusted" = truncation_censoring_fit,
  "Latent variable truncation and censoring adjusted" =
    latent_truncation_censoring_fit
)
```

Extract and summarise lognormal posterior estimates.

```{r lognormal-draws}
draws <- models |>
  map(extract_lognormal_draws) |>
  map(draws_to_long) |>
  rbindlist(idcol = "model") |>
  DT(, model := factor(model, levels = rev(names(models))))

summarised_draws <- summarise_lognormal_draws(draws, sf = 2)

knitr::kable(summarised_draws[parameter %in% c("meanlog", "sdlog")])
```

Plot summarised posterior estimates from each model compared to the ground truth.

```{r, fig.width = 9, fig.height = 4}
draws |>
  make_relative_to_truth(secondary_dist) |>
  plot_relative_recovery(fill = model) +
  facet_wrap(vars(parameter), nrow = 1, scales = "free_x") +
  scale_fill_brewer(palette = "Dark2") +
  guides(fill = guide_none()) +
  labs(
    y = "Model", x = "Relative to ground truth"
  )
```


## Analyses

This analysis in this repository has been implemented using the [`targets`](https://docs.ropensci.org/targets/) package and associated packages. The workflow is defined in [`_targets.md`](https://github.com/parksw3/dynamicaltruncation/blob/main/_targets.md) and can be explored interactively using [`_targets.Rmd`](https://github.com/parksw3/dynamicaltruncation/blob/main/_targets.Rmd) `Rmarkdown` document. The workflow can be visualised as the following graph.


This complete analysis can be recreated using the following (note this may take quite some time even with a fairly large amount of available compute),

```{bash}
bash bin/update-targets.sh
```

Alternative the following `targets` functions may be used to interactively explore the workflow:

- Run the workflow sequentially.

```{r, eval = FALSE}
targets::tar_make()
```

- Run the workflow using all available workers.

```{r, eval = FALSE}
targets::tar_make_future(workers = future::availableCores())
```

- Explore a graph of the workflow.

```{r, eval = FALSE}
targets::tar_visnetwork(targets_only = TRUE)
```

Watch the workflow as it runs in a `shiny` app.

```{r, eval = FALSE}
targets::tar_watch(targets_only = TRUE)
```

To use our archived version of the interim results (and so avoid long run times) use the following to download it. Note that this process has not been rigorously tested across environments and so may not work seamlessly).

```{r, eval = FALSE}
source(here::here("R", "targets-archive.R"))
get_targets_archive()
```