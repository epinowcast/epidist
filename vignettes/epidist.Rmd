---
title: "Getting started with epidist"
description: "A quick start guide to using the epidist R package"
output: 
  bookdown::html_vignette2:
    fig_caption: yes
    code_folding: show
    number_sections: true
pkgdown:
  as_is: true
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa-numeric-superscript-brackets.csl
link-citations: true
vignette: >
  %\VignetteIndexEntry{Getting started with epidist}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
# exclude compile warnings from cmdstanr
knitr::opts_chunk$set(
  fig.path = "figures/getting-started-nowcasting-",
  cache = TRUE,
  dpi = 330,
  collapse = TRUE,
  comment = "#>",
  out.width = "100%",
  message = FALSE,
  warning = FALSE,
  error = FALSE,
  eval = TRUE
)
```

```{r load-requirements}
library(epidist)
library(data.table)
library(purrr)
library(ggplot2)
```

Many quantities in epidemiology can be thought of as the time between two events, or "delays".
Important examples include:

* the incubation period (time between infection and symptom onset),
* serial interval (time between symptom onset of infectee and symptom onset of infected), and 
* generation interval (time between infection of infectee and infection of infected).

Unfortunately, estimating delays accurately from observational data is usually difficult.
In our experience, the two main issues are:

1. interval censoring, and
2. right truncation.

Don't worry if you've not come across these terms before!
In Section \@ref(data), we will explain what they mean by simulating example data analogous to what we might observe during an ongoing infectious disease outbreak.
Next, in Section \@ref(fit), we show how `epidist` can be used to estimate delays using a statistical model which properly accounts for these two issues.
Finally, in Section \@ref(compare), we demonstrate that the fitted delay distribution accurately recovers the underlying truth.

# Example data {#data}

Data should be in a certain format for use within the `epidist` package.
In this section, we simulate data of the appropriate format, and in doing so explain the two main issues with observational delay data.
<!-- Please see as of yet unwritten vignette for information about how to transform your data of other formats to the right format. -->

First, we use the [Gillepsie algorithm](https://en.wikipedia.org/wiki/Gillespie_algorithm) to generate infectious disease outbreak data from a stochastic compartmental model:

```{r}
outbreak <- simulate_gillespie(seed = 101)
```

`outbreak` is a `data.table` with columns for the case number `case` and the time of primary event `ptime`.

Now, to generate secondary events, we will use a lognormal distribution ror the delay between primary and secondary events:

```{r}
secondary_dist <- data.table(meanlog = 1.8, sdlog = 0.5) |>
  add_natural_scale_mean_sd()

obs <- outbreak |>
  simulate_secondary(
    meanlog = secondary_dist[["meanlog"]],
    sdlog = secondary_dist[["sdlog"]]
  )

head(obs)
```

`obs` is a `data.table` object with additional columns for the delay `delay` and time of secondary event `stime`.
The secondary event time is simply the primary event time plus the delay:

```{r}
all(obs$ptime + obs$delay == obs$stime)
```

If we received the data `obs` as above then estimating the delay distribution would be easy, and this package wouldn't need to exist.
However, in reality, we will almost never receive the data as above.

First, the times of primary and secondary events will usually be censored.
This means that rather than exact event times, we observe event times within an interval.
Here we suppose that the interval is daily, resulting in an obscuring of the exact delay data (Figure \@ref(fig:cens)):

```{r}
# observe_process() should be renamed and include a "daily" i.e. 1 argument
obs_cens <- obs |> observe_process()
```

(ref:cens) Interval censoring of the primary and secondary event times obscures the delay times.

```{r cens, fig.cap="(ref:cens)"}
ggplot(obs_cens, aes(x = delay, y = delay_daily)) +
  geom_point(alpha = 0.25) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  theme_minimal() +
  coord_fixed() +
  labs(x = "Exact delay time (days)", y = "Censored delay time (days)")
```

Next, during an outbreak we will usually be estimating delays in real time.
The result is that only those cases with a secondary event occuring before some time will be observed.
This is called (right) truncation, and biases the observation process towards shorter delays:

```{r}
obs_time <- 25
# filter_obs_by_obs_time() should be renamed to refer to stime
obs_cens_trunc <- filter_obs_by_obs_time(obs_cens, obs_time = obs_time)
```

Finally, in reality, it's not possible to observe every case. We suppose that a random sample of individuals of size `sample_size` are observed:

```{r}
sample_size <- 200
```

This sample size corresponds to `r 100 * round(sample_size / nrow(obs_cens_trunc), 3)`% of the data.

```{r}
obs_cens_trunc_samp <- obs_cens_trunc[sample(1:.N, sample_size, replace = FALSE)]
```

With our censored, truncated, and sampled data, we are now ready to attempt to recover the underlying delay distribution using `epidist`.

# Fit the model {#fit}

It would be simple to estimate the delay distribution if we had access to `obs`.
However, with only access to `obs_cens_trunc_samp` we must use a more sophisticated statistical model to ensure that our estimates are not biased.

The primary modelling function in `epidist` to do this is `latent_truncation_censoring_adjusted_delay`.
In a future vignette, we will explain in more detail the structure of the model.
We infer the parameters of the model using Bayesian inference via the No-U-Turn Sampler (NUTS) Markov chain Monte Carlo (MCMC) algorithm.

```{r}
fit <- latent_truncation_censoring_adjusted_delay(
  data = obs_cens_trunc_samp, cores = 4, refresh = 0
)

summary(fit)
```

# Compare estimates {#compare}

Compare modelled estimate to underlying truth here to convince user that it works.
Perhaps as an exercise, we could show the "really simple" estimate being wrong here otherwise it won't be so impressive that the model is right.
This section should also show the user how to get objects that they might want out of the fitted object.

```{r}
draws <- extract_lognormal_draws(fit)
draws_long <- draws_to_long(draws)
summarise_draws(draws_long, sf = 2)
```
