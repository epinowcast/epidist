\documentclass[12pt]{article}
% \usepackage[top=1in,left=1in, right = 1in, footskip=1in]{geometry}
\usepackage[top=1in,footskip=1in]{geometry}

\usepackage{graphicx}
\usepackage{xspace}
%\usepackage{adjustbox}

\usepackage{grffile}

\newcommand{\comment}{\showcomment}
%% \newcommand{\comment}{\nocomment}

\newcommand{\showcomment}[3]{\textcolor{#1}{\textbf{[#2: }\textsl{#3}\textbf{]}}}
\newcommand{\nocomment}[3]{}

\newcommand{\jd}[1]{\comment{cyan}{JD}{#1}}
\newcommand{\swp}[1]{\comment{magenta}{SWP}{#1}}
\newcommand{\bmb}[1]{\comment{blue}{BMB}{#1}}
\newcommand{\djde}[1]{\comment{red}{DJDE}{#1}}

\newcommand{\eref}[1]{Eq.~(\ref{eq:#1})}
\newcommand{\fref}[1]{Fig.~\ref{fig:#1}}
\newcommand{\Fref}[1]{Fig.~\ref{fig:#1}}
\newcommand{\sref}[1]{Sec.~\ref{#1}}
\newcommand{\frange}[2]{Fig.~\ref{fig:#1}--\ref{fig:#2}}
\newcommand{\tref}[1]{Table~\ref{tab:#1}}
\newcommand{\tlab}[1]{\label{tab:#1}}
\newcommand{\seminar}{SE\mbox{$^m$}I\mbox{$^n$}R}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage[utf8]{inputenc} % make sure fancy dashes etc. don't get dropped

\usepackage{lineno}
\linenumbers

\usepackage[pdfencoding=auto, psdextra]{hyperref}

\usepackage{natbib}
\bibliographystyle{unsrt}
\date{\today}

\usepackage{xspace}
\newcommand*{\ie}{i.e.\@\xspace}

\usepackage{color}

\newcommand{\Rx}[1]{\ensuremath{{\mathcal R}_{#1}}\xspace} 
\newcommand{\RR}{\ensuremath{{\mathcal R}}\xspace}
\newcommand{\Rres}{\Rx{\mathrm{res}}}
\newcommand{\Rinv}{\Rx{\mathrm{inv}}}
\newcommand{\Rhat}{\ensuremath{{\hat\RR}}}
\newcommand{\Rt}{\ensuremath{{\mathcal R}(t)}\xspace}
\newcommand{\tsub}[2]{#1_{{\textrm{\tiny #2}}}}
\newcommand{\dd}[1]{\ensuremath{\, \mathrm{d}#1}}
\newcommand{\dtau}{\dd{\tau}}
\newcommand{\dx}{\dd{x}}
\newcommand{\dsigma}{\dd{\sigma}}

\newcommand{\rx}[1]{\ensuremath{{r}_{#1}}\xspace} 
\newcommand{\rres}{\rx{\mathrm{res}}}
\newcommand{\rinv}{\rx{\mathrm{inv}}}

\newcommand{\psymp}{\ensuremath{p}} %% primary symptom time
\newcommand{\ssymp}{\ensuremath{s}} %% secondary symptom time
\newcommand{\pinf}{\ensuremath{\alpha_1}} %% primary infection time
\newcommand{\sinf}{\ensuremath{\alpha_2}} %% secondary infection time

\newcommand{\psize}{{\mathcal P}} %% primary cohort size
\newcommand{\ssize}{{\mathcal S}} %% secondary cohort size

\newcommand{\gtime}{\tau_{\rm g}} %% generation interval
\newcommand{\gdist}{g} %% generation-interval distribution
\newcommand{\idist}{\ell} %% incubation-period distribution

\newcommand{\total}{{\mathcal T}} %% total number of serial intervals

\newcommand{\tend}{{t_{\mathrm{end}}}}
\newcommand{\tmin}{{t_{\mathrm{min}}}}
\newcommand{\tmax}{{t_{\mathrm{max}}}}
\newcommand{\trep}{{t_{\mathrm{rep}}}}
\newcommand{\pmin}{{p_{\mathrm{min}}}}
\newcommand{\pmax}{{p_{\mathrm{max}}}}
\newcommand{\prep}{{p_{\mathrm{rep}}}}
\newcommand{\smin}{{s_{\mathrm{min}}}}
\newcommand{\smax}{{s_{\mathrm{max}}}}
\newcommand{\srep}{{s_{\mathrm{rep}}}}

\usepackage{lettrine}

\newcommand{\dropcapfont}{\fontfamily{lmss}\bfseries\fontsize{26pt}{28pt}\selectfont}
\newcommand{\dropcap}[1]{\lettrine[lines=2,lraise=0.05,findent=0.1em, nindent=0em]{{\dropcapfont{#1}}}{}}

\begin{document}

\begin{flushleft}{
	\Large
	\textbf\newline{
		Adjusting for common biases in infectious disease data when estimating epidemiological delay distributions
	}
}
\newline
\\
Authors
\bigskip

\bigskip

\section*{Abstract}

\end{flushleft}

\pagebreak

\section{Introduction}

\swp{Maybe we don't have to define what a delay distribution is. But I think we need to talk about why these delays are useful and why we should care.}
Epidemiological delay distributions (i.e., the distribution of time between two events associated with infection) provide useful means of summarizing the course of infection, such as disease progression \citep{lauer2020incubation,verity2020estimates} and temporal variation in infectiousness.
\swp{A sentence about using delays to measure NPIS?}
Accurate characterization of epidemiological delay distributions are also critical to understanding population-level outbreak dynamics. \swp{maybe need examples or not.}

Estimating epidemiological delay distributions from data can be challenging due to observational biases.
For example, when the epidemic is ongoing, we cannot observe events that have not happened yet---this \emph{truncation bias}, in turn, causes us to observe shorter intervals and underestimate the mean of the focal distribution.
In addition, event times are often reported in \emph{censored} intervals that can span over a day or even several weeks;
inaccurate estimates of event times can further translate to biases in the estimates of delay distributions.
Recent studies have also highlighted the role of dynamical biases ...

\swp{A paragraph on what's been done. Some people have focused on truncation. Some people on dynamical bias. Some people tried to correct for both. Censoring is also often under-appreciated, at least at a daily time step.}

\section{General theory for estimating epidemiological delay distributions}

\swp{I started writing this section thinking that we need to build up some theory before we introduce actual methods. But now I feel like we can combine this section with the methods section to derive some theory and show likelihood...if that makes sense...}
We present general theory for understanding observational biases in estimating epidemiological delay distributions and derive likelihood for each scenario.
We also provide approximations of each methods, which we compare later.

\subsection{Notation}

Throughout this paper, we use $p$ and $s$ to denote primary and secondary event times, where $s-p$ is the focal epidemiological delay.
In particular we are interested in estimating the forward distribution $f_p(\tau)$, measured from the cohort of individuals who experienced the primary event at the same time $p$.
For now, we focus on the scenario in which the forward distribution remain stable over the course of an epidemic, $f_p(\tau) = f(\tau)$---this is true for many distributions that reflect the course of infection, such as the incubation-period distribution (i.e., time between infection and symptom onset).
Other distributions, such as the generation-interval distribution (i.e., time between infection and transmission) and reporting distributions, are expected to change throughout.
While it is possible (and perhaps more convenient) to characterize the backward distribution $b_s(\tau)$, measured from the cohort of individuals who experienced the secondary event at the same time $s$, these distributions are subject to dynamical biases as we discuss later.

\subsection{Accounting for truncation bias}

When an epidemic is ongoing, we cannot observe events that have not happened yet.
Therefore, in order to observe ...
Then, the likelihood of observing a delay of $X_i$ from the right-truncated distribution is given by:
\begin{equation}
\mathcal L(\theta|X_i) = \frac{f(X_i)}{F(\tend-p)}.
\end{equation}

\subsection{Accounting for censoring bias}

There are broadly two kinds of censoring in epidemic data: explicit and implicit.
Explicit censoring refers to a scenario in which a focal event is reported as having occurred within a censored interval between $\tmin$ and $\tmax$.
For example, infection events are often explicitly censored because the exact timing of infection is difficult to identify.
Implicit censoring refers to a scenario in which focal events that occur between some interval are reported as having occurred at a specific time point $\trep$.
For example, an individual who developed symptoms on a given day could have started showing symptoms at any time within the 24 hour cycle.
\swp{would be good to mention that people often ignore the implicit censoring}
In this paper, we will be primarily dealing with censoring that occurs at a daily time step and therefore will focus on implicit censoring---the implicit censoring also allows for a convenient framing of the problem as we will show here.

Here, we take the cohort-based approach to understanding censored data.
We begin by assuming that an individual who experiences a focal event at time $\tmin leq t < \tmax$ has a probability $g_t(\trep)$ of having their event reported at time $\trep$.
Then, for a cohort of individuals who reported the focal event at time $\trep$, the distribution of their true event time $\pi(t)$ depend on the reporting distribution $g_t(\trep)$ as well as the incidence of focal event $i(t)$:
\begin{equation}
\pi(t) = \frac{i(t) g_t(\trep)}{\int_{\tmin}^\tmax i(z) g_z(\trep) \dd z}.
\end{equation}
For example, for an idealized daily reporting scenario, in which all events happening at time $n \leq t < n+1$ is reported as having occurred at time $n$, the reporting distribution corresponds to $g_t(n) = 1$ for $n \leq t < n+1$;
in this case, if we further assume that the incidence is exponentially changing at rate $r$, the distribution of their true event time simplifies to:
\begin{equation}
\pi(t) = \frac{\exp(rt)}{\exp(nr) (\exp(r) - 1)/r}.
\end{equation}
We note that the denominator can be ignored in the likelihood for the purpose of parameter estimation because it is a constant value.

Finally, given that primary and secondary events are reported at time $P_i$ and $S_i$, respectively, the likelihood of this data is given by:
\begin{equation}
\mathcal L(\theta|P_i, S_i) = \int_{S_i}^{S_i+1} \int_{P_i}^{P_i+1} \pi_s(t_2) \pi_p(t_1) f(t_2-t_1) \dd t_1 \dd t_2,
\end{equation}
where $t_1$ and $t_2$ represent latent variables for the timing of primary and secondary events, respectively;
and $\pi_p$ and $\pi_s$ represent distributions of the true timing of primary and secondary events, respectively.
Other studies have typically assumed uniform distributions for $\pi$, thereby neglecting underlying epidemioligical dynamics.
\swp{Need to say we're going to compare uniform vs exponential?}

\subsection{Accounting for both truncation and censoring bias}

Correct method:
\begin{equation}
\mathcal L(\theta|P_i, S_i) = \int_{S_i}^{S_i+1} \int_{P_i}^{P_i+1} \pi_s(t_2) \pi_p(t_1) \frac{f(t_2 - t_1)}{F_p(\tend-t_1)} \dd t_1 \dd t_2
\end{equation}

The correct method is complex because we have to rely on latent variables. In particular, the truncation time now depends on censoring. Instead, we can approximate using half-points and what not...

\section{Implementation}

\begin{itemize}
  \item Let's define likelihood with theory in the previous section
  \item Primarily focus on actual implementation here. Stan, brms, blah blah blah
\end{itemize}

\section{Simulation study}

\section{Case study with real data}

\section{Discussion}

\pagebreak

\bibliography{dynamicaltruncation}

\end{document}
